{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6664c4f-2d18-4a42-a0f5-c077f1a621d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\visma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting legal text...\n",
      "Building FAISS index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\visma\\AppData\\Local\\Temp\\ipykernel_7412\\2998157115.py:163: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "C:\\Users\\visma\\AppData\\Local\\Temp\\ipykernel_7412\\2998157115.py:163: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Customs Hybrid Chatbot Ready. Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "🗨️ You:  cotton and silk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Bot: Mules and hinnies as livestock → CHAPTER 1 – Live animals\n",
      "HS Code: 01019030 | Policy: Restricted           | Duty: Refer to schedule\n",
      "Whales, dolphins and porpoises (mammals of the order Cetacea); manatees and dugongs (mammals of the order Sirenia); seals, sea lions and walruses (mammals of the suborder Pinnipedia) → CHAPTER 1 – Live animals\n",
      "HS Code: 01061200 | Policy: Restricted           | Duty: Refer to schedule\n",
      "Camels and other camelids (Camelidae) → CHAPTER 1 – Live animals\n",
      "HS Code: 01061300 | Policy: Restricted           | Duty: Refer to schedule\n",
      "📘 Refer to relevant chapters.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "🗨️ You:  exit\n"
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import difflib\n",
    "from PyPDF2 import PdfReader\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk; nltk.download(\"punkt\")\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# --- Load Data ---\n",
    "df = pd.read_excel(\"C:/Users/visma/Downloads/ITCHS_2012.xls\", dtype=str)\n",
    "\n",
    "# --- Term Mapping ---\n",
    "term_mapping = defaultdict(list)\n",
    "corpus = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    hs = str(row[\"ITC(HS)\"]).strip()\n",
    "    desc = str(row[\"Description\"]).strip()\n",
    "    chapter = int(hs[:2])\n",
    "    policy = row.get(\"Policy\", \"Unknown\")\n",
    "\n",
    "    entry = {\n",
    "        \"hs_code\": hs,\n",
    "        \"desc\": desc,\n",
    "        \"chapter\": chapter,\n",
    "        \"policy\": policy,\n",
    "        \"duty\": \"Refer to schedule\",\n",
    "        \"note\": \"Auto-mapped\"\n",
    "    }\n",
    "\n",
    "    # full phrase\n",
    "    term_mapping[desc.lower()].append(entry)\n",
    "    # tokenized words\n",
    "    for word in word_tokenize(desc.lower()):\n",
    "        if word.isalpha() and len(word) > 2:\n",
    "            term_mapping[word].append(entry)\n",
    "\n",
    "    corpus.append(desc)\n",
    "\n",
    "# --- Chapter Dictionary ---\n",
    "chapter_dict = {\n",
    "    \"chapter 1\": \"Live animals\",\n",
    "    \"chapter 2\": \"Meat and edible meat offal\",\n",
    "    \"chapter 3\": \"Fish and crustaceans, molluscs and other aquatic invertebrates\",\n",
    "    \"chapter 4\": \"Dairy produce; birds' eggs; natural honey; edible products of animal origin\",\n",
    "    \"chapter 5\": \"Products of animal origin, not elsewhere specified or included\",\n",
    "    \"chapter 6\": \"Live trees and other plants; bulbs, roots and the like; cut flowers and ornamental foliage\",\n",
    "    \"chapter 7\": \"Edible vegetables and certain roots and tubers\",\n",
    "    \"chapter 8\": \"Edible fruit and nuts; peel of citrus fruit or melons\",\n",
    "    \"chapter 9\": \"Coffee, tea, mate and spices\",\n",
    "    \"chapter 10\": \"Cereals\",\n",
    "    \"chapter 11\": \"Products of the milling industry; malt; starches; inulin; wheat gluten\",\n",
    "    \"chapter 12\": \"Oil seeds and oleaginous fruits; miscellaneous grains, seeds and fruit\",\n",
    "    \"chapter 13\": \"Lac; gums, resins and other vegetable saps and extracts\",\n",
    "    \"chapter 14\": \"Vegetable plaiting materials; vegetable products not elsewhere specified or included\",\n",
    "    \"chapter 15\": \"Animal or vegetable fats and oils and their cleavage products\",\n",
    "    \"chapter 16\": \"Preparations of meat, of fish or of crustaceans, molluscs or other aquatic invertebrates\",\n",
    "    \"chapter 17\": \"Sugars and sugar confectionery\",\n",
    "    \"chapter 18\": \"Cocoa and cocoa preparations\",\n",
    "    \"chapter 19\": \"Preparations of cereals, flour, starch or milk\",\n",
    "    \"chapter 20\": \"Preparations of vegetables, fruit, nuts or other parts of plants\",\n",
    "    \"chapter 21\": \"Miscellaneous edible preparations\",\n",
    "    \"chapter 22\": \"Beverages, spirits and vinegar\",\n",
    "    \"chapter 23\": \"Residues and waste from the food industries; prepared animal fodder\",\n",
    "    \"chapter 24\": \"Tobacco and manufactured tobacco substitutes\",\n",
    "    \"chapter 25\": \"Salt; sulphur; earths and stone; plastering materials, lime and cement\",\n",
    "    \"chapter 26\": \"Ores, slag and ash\",\n",
    "    \"chapter 27\": \"Mineral fuels, mineral oils and products of their distillation\",\n",
    "    \"chapter 28\": \"Inorganic chemicals; organic or inorganic compounds of precious metals\",\n",
    "    \"chapter 29\": \"Organic chemicals\",\n",
    "    \"chapter 30\": \"Pharmaceutical products\",\n",
    "    \"chapter 31\": \"Fertilizers\",\n",
    "    \"chapter 32\": \"Tanning or dyeing extracts; tannins and their derivatives\",\n",
    "    \"chapter 33\": \"Essential oils and resinoids; perfumery, cosmetic or toilet preparations\",\n",
    "    \"chapter 34\": \"Soap, organic surface-active agents, washing preparations\",\n",
    "    \"chapter 35\": \"Albuminoidal substances; modified starches; glues; enzymes\",\n",
    "    \"chapter 36\": \"Explosives; pyrotechnic products; matches; pyrophoric alloys\",\n",
    "    \"chapter 37\": \"Photographic or cinematographic goods\",\n",
    "    \"chapter 38\": \"Miscellaneous chemical products\",\n",
    "    \"chapter 39\": \"Plastics and articles thereof\",\n",
    "    \"chapter 40\": \"Rubber and articles thereof\",\n",
    "    \"chapter 41\": \"Raw hides and skins (other than furskins) and leather\",\n",
    "    \"chapter 42\": \"Articles of leather; saddlery and harness\",\n",
    "    \"chapter 43\": \"Furskins and artificial fur; manufactures thereof\",\n",
    "    \"chapter 44\": \"Wood and articles of wood\",\n",
    "    \"chapter 45\": \"Cork and articles of cork\",\n",
    "    \"chapter 46\": \"Manufactures of straw, of esparto or of other plaiting materials\",\n",
    "    \"chapter 47\": \"Pulp of wood or of other fibrous cellulosic material\",\n",
    "    \"chapter 48\": \"Paper and paperboard; articles of paper pulp\",\n",
    "    \"chapter 49\": \"Printed books, newspapers, pictures and other products\",\n",
    "    \"chapter 50\": \"Silk\",\n",
    "    \"chapter 51\": \"Wool, fine or coarse animal hair\",\n",
    "    \"chapter 52\": \"Cotton\",\n",
    "    \"chapter 53\": \"Other vegetable textile fibres; paper yarn and woven fabrics\",\n",
    "    \"chapter 54\": \"Man-made filaments\",\n",
    "    \"chapter 55\": \"Man-made staple fibres\",\n",
    "    \"chapter 56\": \"Wadding, felt and nonwovens\",\n",
    "    \"chapter 57\": \"Carpets and other textile floor coverings\",\n",
    "    \"chapter 58\": \"Special woven fabrics; tufted textile fabrics\",\n",
    "    \"chapter 59\": \"Impregnated, coated, covered or laminated textile fabrics\",\n",
    "    \"chapter 60\": \"Knitted or crocheted fabrics\",\n",
    "    \"chapter 61\": \"Articles of apparel and clothing accessories, knitted or crocheted\",\n",
    "    \"chapter 62\": \"Articles of apparel and clothing accessories, not knitted or crocheted\",\n",
    "    \"chapter 63\": \"Other made up textile articles\",\n",
    "    \"chapter 64\": \"Footwear, gaiters and the like\",\n",
    "    \"chapter 65\": \"Headgear and parts thereof\",\n",
    "    \"chapter 66\": \"Umbrellas, sun umbrellas, walking sticks\",\n",
    "    \"chapter 67\": \"Prepared feathers and down\",\n",
    "    \"chapter 68\": \"Articles of stone, plaster, cement, asbestos, mica\",\n",
    "    \"chapter 69\": \"Ceramic products\",\n",
    "    \"chapter 70\": \"Glass and glassware\",\n",
    "    \"chapter 71\": \"Natural or cultured pearls, precious or semi-precious stones\",\n",
    "    \"chapter 72\": \"Iron and steel\",\n",
    "    \"chapter 73\": \"Articles of iron or steel\",\n",
    "    \"chapter 74\": \"Copper and articles thereof\",\n",
    "    \"chapter 75\": \"Nickel and articles thereof\",\n",
    "    \"chapter 76\": \"Aluminium and articles thereof\",\n",
    "    \"chapter 77\": \"Reserved for future use\",\n",
    "    \"chapter 78\": \"Lead and articles thereof\",\n",
    "    \"chapter 79\": \"Zinc and articles thereof\",\n",
    "    \"chapter 80\": \"Tin and articles thereof\",\n",
    "    \"chapter 81\": \"Other base metals; cermets\",\n",
    "    \"chapter 82\": \"Tools, implements, cutlery, spoons and forks\",\n",
    "    \"chapter 83\": \"Miscellaneous articles of base metal\",\n",
    "    \"chapter 84\": \"Nuclear reactors, boilers, machinery and mechanical appliances\",\n",
    "    \"chapter 85\": \"Electrical machinery and equipment\",\n",
    "    \"chapter 86\": \"Railway or tramway locomotives, rolling stock and parts\",\n",
    "    \"chapter 87\": \"Vehicles other than railway or tramway\",\n",
    "    \"chapter 88\": \"Aircraft, spacecraft, and parts thereof\",\n",
    "    \"chapter 89\": \"Ships, boats and floating structures\",\n",
    "    \"chapter 90\": \"Optical, photographic, cinematographic, measuring, medical instruments\",\n",
    "    \"chapter 91\": \"Clocks and watches and parts thereof\",\n",
    "    \"chapter 92\": \"Musical instruments\",\n",
    "    \"chapter 93\": \"Arms and ammunition; parts and accessories thereof\",\n",
    "    \"chapter 94\": \"Furniture; bedding, mattresses, cushions\",\n",
    "    \"chapter 95\": \"Toys, games and sports requisites\",\n",
    "    \"chapter 96\": \"Miscellaneous manufactured articles\",\n",
    "    \"chapter 97\": \"Works of art, collectors’ pieces and antiques\",\n",
    "    \"chapter 98\": \"Project imports, special classification provisions\"\n",
    "}\n",
    "\n",
    "# --- Sentence Embeddings ---\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# --- FAISS Fallback ---\n",
    "def extract_text_from_pdf(path):\n",
    "    reader = PdfReader(path)\n",
    "    return \"\\n\".join([p.extract_text() for p in reader.pages if p.extract_text()])\n",
    "\n",
    "def build_faiss_index(text):\n",
    "    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunks = splitter.split_text(text)\n",
    "    docs = [Document(page_content=c) for c in chunks]\n",
    "    embeddings = HuggingFaceEmbeddings()\n",
    "    return FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# --- Semantic Handler ---\n",
    "def semantic_search(query):\n",
    "    query_embed = model.encode(query, convert_to_tensor=True)\n",
    "    hits = util.semantic_search(query_embed, corpus_embeddings, top_k=3)[0]\n",
    "    results = []\n",
    "\n",
    "    for h in hits:\n",
    "        data = term_mapping[corpus[h[\"corpus_id\"]].lower()][0]\n",
    "        chapter_name = chapter_dict.get(f\"chapter {data['chapter']}\", \"Unknown\")\n",
    "        results.append(\n",
    "            f\"{data['desc']} → CHAPTER {data['chapter']} – {chapter_name}\\n\"\n",
    "            f\"HS Code: {data['hs_code']} | Policy: {data['policy']} | Duty: {data['duty']}\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "# --- Synonym Dictionary (expandable) ---\n",
    "synonyms = {\n",
    "    \"gold\": [\"precious metal\", \"bullion\"],\n",
    "    \"missile\": [\"rocket\", \"projectile\"],\n",
    "    \"drone\": [\"uav\", \"quadcopter\", \"suicide drone\"],\n",
    "}\n",
    "\n",
    "# --- Hybrid Handler ---\n",
    "def handle_query(query, faiss_index):\n",
    "    q = query.lower()\n",
    "    q_tokens = set(word_tokenize(q))\n",
    "    \n",
    "    # 1. Synonym Expansion\n",
    "    for token in list(q_tokens):\n",
    "        if token in synonyms:\n",
    "            q_tokens.update(synonyms[token])\n",
    "\n",
    "    # 2. Multi-keyword combination match \n",
    "combined_matches = []\n",
    "for token in q_tokens:\n",
    "    if token in term_mapping:\n",
    "        combined_matches.extend(term_mapping[token])\n",
    "\n",
    "# Filter for items that match multiple tokens\n",
    "if len(q_tokens) > 1:\n",
    "    filtered = []\n",
    "    for entry in combined_matches:\n",
    "        matched_words = [word for word in q_tokens if word in entry[\"desc\"].lower()]\n",
    "        if len(matched_words) >= 2:  # Match at least 2 keywords\n",
    "            filtered.append(entry)\n",
    "\n",
    "    if filtered:\n",
    "        seen = set()\n",
    "        results = []\n",
    "        for item in sorted(filtered, key=lambda x: (x[\"chapter\"], x[\"hs_code\"])):\n",
    "            if item[\"hs_code\"] in seen:\n",
    "                continue\n",
    "            seen.add(item[\"hs_code\"])\n",
    "            chapter_name = chapter_dict.get(f\"chapter {item['chapter']}\", \"Unknown\")\n",
    "            results.append(\n",
    "                f\"{item['desc']} → CHAPTER {item['chapter']} – {chapter_name}\\n\"\n",
    "                f\"HS Code: {item['hs_code']} | Policy: {item['policy']} | Duty: {item['duty']}\"\n",
    "            )\n",
    "        return \"\\n\".join(results[:3]) + \"\\n📘 Refer to relevant chapters.\"\n",
    "\n",
    "\n",
    "    # 3. Fuzzy Match\n",
    "    all_terms = list(term_mapping.keys())\n",
    "    fuzz = difflib.get_close_matches(q, all_terms, n=1, cutoff=0.7)\n",
    "    if fuzz:\n",
    "        result = term_mapping[fuzz[0]][0]\n",
    "        chapter_name = chapter_dict.get(f\"chapter {result['chapter']}\", \"Unknown\")\n",
    "        return (\n",
    "            f\"{fuzz[0]} → CHAPTER {result['chapter']} – {chapter_name}\\n\"\n",
    "            f\"HS Code: {result['hs_code']} | Policy: {result['policy']} | Duty: {result['duty']}\"\n",
    "        )\n",
    "\n",
    "    # 4. Semantic Match\n",
    "    return \"🔍 \" + semantic_search(query)\n",
    "\n",
    "# --- Local Run ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Extracting legal text...\")\n",
    "    full_text = extract_text_from_pdf(\"C:/Users/visma/OneDrive/Desktop/project cahtbot/a197551.pdf\" )\n",
    "    print(\"Building FAISS index...\")\n",
    "    faiss_index = build_faiss_index(full_text)\n",
    "\n",
    "    print(\"🚀 Customs Hybrid Chatbot Ready. Type 'exit' to stop.\")\n",
    "    while True:\n",
    "        q = input(\"🗨️ You: \")\n",
    "        if q.lower() == \"exit\":\n",
    "            break\n",
    "        answer = handle_query(q, faiss_index)\n",
    "        print(f\"🤖 Bot: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f61b01-672b-416b-b758-e8942d168bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
